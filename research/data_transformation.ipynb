{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce4a46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amil\\\\OneDrive\\\\Documents\\\\Data_Science_end_to_end_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247b40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "from src import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.constants import *\n",
    "from src.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8c4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir : Path\n",
    "    data_path : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36cfded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManger:\n",
    "    def __init__(self,\n",
    "                config_path= CONFIG_FILE_PATH,\n",
    "                params_path= PARAMS_FILE_PATH,\n",
    "                schema_path = SCHEMA_FILE_PATH\n",
    "                ):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "        self.schema = read_yaml(schema_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_transformation_config(self)-> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            data_path= config.data_path\n",
    "        )\n",
    "        \n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ce4c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def load_data(self)-> pd.DataFrame :\n",
    "        \"\"\"\n",
    "        Load dataset from the configured path.\n",
    "        \"\"\"\n",
    "        try :\n",
    "            data = pd.read_csv(self.config.data_path)\n",
    "            logger.info(f\"Data loaded successfully from {self.config.data_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            raise e\n",
    "    \n",
    "    def check_missing_values(self,data : pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Check for missing values and log them.\n",
    "        \"\"\"\n",
    "        missing_values = data.isnull().sum()\n",
    "        logger.info(f\"Missing values per column:\\n{missing_values}\")\n",
    "        return missing_values\n",
    "    \n",
    "    def generate_summary_statistics(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generate and save summary statistics like mean, median, std, etc.\n",
    "        \"\"\"\n",
    "        \n",
    "        try :\n",
    "            summary = data.describe().T\n",
    "            summary_path = Path(self.config.root_dir,\"summary.csv\")\n",
    "            summary.to_csv(summary_path)\n",
    "            logger.info(f\"Summary statistics saved at {summary_path}\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary statistics: {e}\")\n",
    "            raise e\n",
    "        \n",
    "    def train_test_split(self, data: pd.DataFrame):\n",
    "        \n",
    "        train,test = train_test_split(data,test_size=0.2,random_state=42)\n",
    "        \n",
    "        train.to_csv(os.path.join(self.config.root_dir,\"train.csv\"), index = False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir,\"test.csv\"), index = False)\n",
    "        \n",
    "        logger.info(f\"Splitted the data into training and test\")\n",
    "        \n",
    "        logger.info(train.shape)\n",
    "        logger.info(test.shape)\n",
    "        \n",
    "    \n",
    "    def perform_full_eda(self):\n",
    "        \"\"\"\n",
    "        Perform full EDA pipeline:\n",
    "        1. Load data\n",
    "        2. Check missing values\n",
    "        3. Generate summary statistics\n",
    "        4. Detect outliers\n",
    "        5. Correlation analysis\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting EDA process...\")\n",
    "        data = self.load_data()\n",
    "        \n",
    "        # Step 1: Missing Values\n",
    "        self.check_missing_values(data)\n",
    "        \n",
    "        # Step 2: Summary Statistics\n",
    "        self.generate_summary_statistics(data)\n",
    "        \n",
    "        #step 3: train test split\n",
    "        \n",
    "        self.train_test_split(data)\n",
    "        \n",
    "        logger.info(f\"completed the EDA\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32c9d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-25 22:59:30,850:, INFO:, common:, yaml file : config\\config.yaml loaded successfully]\n",
      "[2025-09-25 22:59:30,905:, INFO:, common:, yaml file : params.yaml loaded successfully]\n",
      "[2025-09-25 22:59:30,915:, INFO:, common:, yaml file : schema.yaml loaded successfully]\n",
      "[2025-09-25 22:59:30,950:, INFO:, common:, created directory for artifacts]\n",
      "[2025-09-25 22:59:30,961:, INFO:, common:, created directory for artifacts/data_transformation]\n",
      "[2025-09-25 22:59:30,964:, INFO:, 1747196797:, Starting EDA process...]\n",
      "[2025-09-25 22:59:31,496:, INFO:, 1747196797:, Data loaded successfully from artifacts/data_ingestion/winequality-red.csv]\n",
      "[2025-09-25 22:59:31,556:, INFO:, 1747196797:, Missing values per column:\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64]\n",
      "[2025-09-25 22:59:31,633:, INFO:, 1747196797:, Summary statistics saved at artifacts\\data_transformation\\summary.csv]\n",
      "[2025-09-25 22:59:31,703:, INFO:, 1747196797:, Splitted the data into training and test]\n",
      "[2025-09-25 22:59:31,705:, INFO:, 1747196797:, (1279, 12)]\n",
      "[2025-09-25 22:59:31,706:, INFO:, 1747196797:, (320, 12)]\n",
      "[2025-09-25 22:59:31,707:, INFO:, 1747196797:, completed the EDA]\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    config = ConfigurationManger()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config= data_transformation_config)\n",
    "    data_transformation.perform_full_eda()\n",
    "except Exception as e:\n",
    "    logger.info(e)\n",
    "    raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ba2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
